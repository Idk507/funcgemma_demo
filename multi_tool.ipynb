{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bdb122a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from transformers import AutoModelForCausalLM, AutoProcessor , AutoTokenizer\n",
    "from datetime import datetime \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "176aae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"google/functiongemma-270m-it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6933974",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoProcessor.from_pretrained(\"google/functiongemma-270m-it\", device_map=\"auto\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"google/functiongemma-270m-it\", dtype=\"auto\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2d946a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoProcessor.from_pretrained(path, device_map = \"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "99dcc7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_today_date():\n",
    "    \"\"\"\n",
    "    Gets today's date\n",
    "\n",
    "    Returns:\n",
    "        today_date: Today's date in format 18 December 2025\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "    today_date = datetime.today().strftime(\"%d %B %Y\")\n",
    "    return {\"today_date\": today_date}\n",
    "\n",
    "def get_current_weather(location: str, unit: str = \"celsius\"):\n",
    "    \"\"\"\n",
    "    Gets the current weather in a given location.\n",
    "\n",
    "    Args:\n",
    "        location: The city and state, e.g. \"San Francisco, CA, USA\" or \"Sydney, Australia\"\n",
    "        unit: The unit to return the temperature in. (choices: [\"celsius\", \"fahrenheit\"])\n",
    "\n",
    "    Returns:\n",
    "        temperature: The current temperature in the given location\n",
    "        weather: The current weather in the given location\n",
    "    \"\"\"\n",
    "    if \"San Francisco\" in location.title():\n",
    "        return {\"temperature\": 15, \"weather\": \"sunny\"}\n",
    "    elif \"Sydney\" in location.title():\n",
    "        return {\"temperature\": 25, \"weather\": \"cloudy\"}\n",
    "    else:\n",
    "        return {\"temperature\": 30, \"weather\": \"rainy\"}\n",
    "\n",
    "def add_numbers(x: float | str, y: float | str):\n",
    "    \"\"\"\n",
    "    Adds 2 numbers together\n",
    "\n",
    "    Args:\n",
    "        x: First number\n",
    "        y: Second number\n",
    "\n",
    "    Returns:\n",
    "        result: x + y\n",
    "    \"\"\"\n",
    "    return {\"result\" : float(x) + float(y)}\n",
    "\n",
    "def multiply_numbers(x: float | str, y: float | str):\n",
    "    \"\"\"\n",
    "    Multiplies 2 numbers together\n",
    "\n",
    "    Args:\n",
    "        x: First number\n",
    "        y: Second number\n",
    "\n",
    "    Returns:\n",
    "        result: x * y\n",
    "    \"\"\"\n",
    "    return {\"result\" : float(x) * float(y)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9302ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FUNCTION_MAPPING = {\n",
    "    \"get_today_date\" : get_today_date,\n",
    "    \"get_current_weather\" : get_current_weather,\n",
    "    \"add_numbers\": add_numbers,\n",
    "    \"multiply_numbers\": multiply_numbers,\n",
    "}\n",
    "TOOLS = list(FUNCTION_MAPPING.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51274615",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOLS =  list(FUNCTION_MAPPING.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3fe58574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tool_calls(text):\n",
    "    def cast(v):\n",
    "        try: return int(v)\n",
    "        except:\n",
    "            try: return float(v)\n",
    "            except: return {'true': True, 'false': False}.get(v.lower(), v.strip(\"'\\\"\"))\n",
    "\n",
    "    return [{\n",
    "        \"name\": name,\n",
    "        \"arguments\": {\n",
    "            k: cast((v1 or v2).strip())\n",
    "            for k, v1, v2 in re.findall(r\"(\\w+):(?:<escape>(.*?)<escape>|([^,}]*))\", args)\n",
    "        }\n",
    "    } for name, args in re.findall(r\"<start_function_call>call:(\\w+)\\{(.*?)\\}<end_function_call>\", text, re.DOTALL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4104ce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tool_calls(output, messages):\n",
    "    calls = extract_tool_calls(output)\n",
    "    if not calls :\n",
    "        return messages\n",
    "    messages.append({\n",
    "        \"role\" : \"assistant\",\n",
    "        \"tool_calls\" : [{\"type\" : \"function\", \"function\" : call} for call in calls]\n",
    "    })\n",
    "    results = [\n",
    "        {\n",
    "            \"name\" : c[\"name\"] , \"response\" : FUNCTION_MAPPING[c['name']](**c['arguments'])\n",
    "        } for c in calls\n",
    "    ]\n",
    "    messages.append({\"role\" : \"tool\",\"content\" : results})\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a751dda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _do_inference(model, messages, max_new_tokens = 128):\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages, tools = TOOLS, add_generation_prompt = True, return_dict = True, return_tensors = \"pt\",\n",
    "    )\n",
    "    output = tokenizer.decode(inputs[\"input_ids\"][0], skip_special_tokens = False)\n",
    "\n",
    "    out = model.generate(**inputs.to(model.device), max_new_tokens = max_new_tokens,\n",
    "                         top_p = 0.95, top_k = 64, temperature = 1.0,)\n",
    "    generated_tokens = out[0][len(inputs[\"input_ids\"][0]):]\n",
    "    return tokenizer.decode(generated_tokens, skip_special_tokens = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "257374d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_inference(model, messages, print_assistant = True, max_new_tokens = 128):\n",
    "    output = _do_inference(model, messages, max_new_tokens = max_new_tokens)\n",
    "    messages = process_tool_calls(output, messages)\n",
    "    if messages[-1][\"role\"] == \"tool\":\n",
    "        output = _do_inference(model, messages, max_new_tokens = max_new_tokens)\n",
    "    messages.append({\"role\": \"assistant\", \"content\": output})\n",
    "    if print_assistant: print(output)\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "95b4b866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current date is 25 December 2025.\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"user\", \"content\": \"What's today's date?\"})\n",
    "messages = do_inference(model, messages, max_new_tokens = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e9e0e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in San Francisco is:\n",
      "\n",
      "*   **Temperature:** 15\n",
      "*   **Weather:** Sunny\n",
      "*   **Temperature:** 15\n",
      "*   **Other details:** The weather is sunny.\n"
     ]
    }
   ],
   "source": [
    "messages.append({\"role\" : \"user\", \"content\" : \"What's the weather like in San Francisco?\"})\n",
    "messages = do_inference(model, messages, max_new_tokens = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e761b988",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
